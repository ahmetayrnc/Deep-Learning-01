{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06ab2292"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_1/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>    "
      ],
      "id": "06ab2292"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9b20982"
      },
      "source": [
        "# Group Number: 47\n",
        "# Student 1: Ahmet Ayrancioglu\n",
        "# Student 2: Ricardo Andrade\n",
        "# Student 3: Ruben Wolters"
      ],
      "id": "b9b20982"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "7c03FZYN_lAz"
      },
      "id": "7c03FZYN_lAz"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b49fc2e3",
        "outputId": "c1e630de-7b00-4d67-f5d7-246c15015266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "%pylab inline"
      ],
      "id": "b49fc2e3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25cfb295"
      },
      "source": [
        "### Training data set\n",
        "\n",
        "\n",
        "For Assignment 1 you need to use a specific data set prepared using images from the [Omniglot dataset](https://github.com/brendenlake/omniglot). The provided training data set contains images of handwritten characters of size (28,28). \n",
        "\n",
        "\n",
        "\n",
        "For training data, the dataset contains 10000 sets of 6 images each. Each set consists of 5 support images and 1 query image. In each set, the first five columns are support images and the last one is a query image.\n",
        "\n",
        "For training labels, the dataset contains 10000 sets of 5 binary flags for support images. 1 indicates the same character is given in the query image and 0 means not. For example, a label [1,0,0,1,1] means the support images with index 0,3,4 are the same character of query image.\n",
        "\n",
        " \n",
        " \n",
        "The following cell provides code that loads the data from hardcoded URLs.You can use the code in this cell to load the dataset or download the data set from the given URLs to your local drive (or your Google drive) and modify the code to load the data from another location. \n",
        "\n",
        "\n"
      ],
      "id": "25cfb295"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f19f0a40",
        "outputId": "98958040-2a5b-42f4-ed15-7c20fd55fc01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data shape: (10000, 6, 28, 28)\n",
            "train_label shape: (10000, 5)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def load_numpy_arr_from_url(url):\n",
        "    \"\"\"\n",
        "    Loads a numpy array from surfdrive. \n",
        "    \n",
        "    Input:\n",
        "    url: Download link of dataset \n",
        "    \n",
        "    Outputs:\n",
        "    dataset: numpy array with input features or labels\n",
        "    \"\"\"\n",
        "    \n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    return np.load(io.BytesIO(response.content)) \n",
        "    \n",
        "    \n",
        "    \n",
        "#Downloading may take a while..\n",
        "train_data = load_numpy_arr_from_url('https://surfdrive.surf.nl/files/index.php/s/4OXkVie05NPjRKK/download')\n",
        "train_label = load_numpy_arr_from_url('https://surfdrive.surf.nl/files/index.php/s/oMLFw60zpFX82ua/download')\n",
        "\n",
        "print(f\"train_data shape: {train_data.shape}\")\n",
        "print(f\"train_label shape: {train_label.shape}\\n\")"
      ],
      "id": "f19f0a40"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb937392"
      },
      "source": [
        "Now, we plot the first 5 cases in the training dataset. The last column corresponds with the query images of each task. All other images are support images. The image enclosed in a red box denotes the target image that your model should be able to recognize as the same class as the query image. "
      ],
      "id": "cb937392"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b1b4bd29"
      },
      "outputs": [],
      "source": [
        "def plot_case(caseID,train_data,labels):\n",
        "    \"\"\"\n",
        "    Plots a single sample of the query dataset\n",
        "    \n",
        "    Inputs\n",
        "    caseID: Integer between 0 and 99, each corresponding to a single sample in the query dataset \n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    support_set,queries = np.split(train_data, [5], axis=1)\n",
        "    \n",
        "    f, axes = plt.subplots(1, 6, figsize=(20,5))\n",
        "\n",
        "    # plot anchor image\n",
        "    axes[5].imshow(queries[caseID, 0])\n",
        "    axes[5].set_title(f\"Query image case {caseID}\", fontsize=15)\n",
        "\n",
        "    # show all test images images \n",
        "    [ax.imshow(support_set[caseID, i]) for i, ax in enumerate(axes[0:-1])]\n",
        "\n",
        "\n",
        "    # Add the patch to the Axes\n",
        "    for ind in np.where(labels[caseID]==True)[0]:\n",
        "        axes[ind].add_patch(Rectangle((0,0),27,27,linewidth=2, edgecolor='r',facecolor='none'))\n"
      ],
      "id": "b1b4bd29"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "03538ffb"
      },
      "outputs": [],
      "source": [
        "# [plot_case(caseID,train_data,train_label) for caseID in range(5)] ;"
      ],
      "id": "03538ffb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "931f2383"
      },
      "source": [
        "### Query data set\n",
        "\n",
        "For this task you need to use the following query data set. The dataset contains 1000 sets of 6 images each. The images are also of hand written characters, however these characters are not present in the training data set. The characters in the query data set all come from the Greek alphabet that is not part of the set of alphabets in the training data. \n"
      ],
      "id": "931f2383"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9ba78dc",
        "outputId": "2754b162-98f0-457f-aa66-223240ddf52f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_data shape: (1000, 6, 28, 28)\n",
            "test_label shape: (1000, 5)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "    \n",
        "#Downloading may take a while..\n",
        "test_data = load_numpy_arr_from_url('https://surfdrive.surf.nl/files/index.php/s/06c34QVUr69CxWY/download')\n",
        "test_label = load_numpy_arr_from_url('https://surfdrive.surf.nl/files/index.php/s/LQIH1CW7lfDXevk/download')\n",
        "\n",
        "print(f\"test_data shape: {test_data.shape}\")\n",
        "print(f\"test_label shape: {test_label.shape}\\n\")"
      ],
      "id": "c9ba78dc"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "03fb3580",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# [plot_case(caseID,test_data,test_label) for caseID in range(5)] ;"
      ],
      "id": "03fb3580"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcc32db2"
      },
      "source": [
        "## Build pytorch dataset and dataload"
      ],
      "id": "fcc32db2"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fcf31f45"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import itertools\n",
        "\n",
        "# This dataset is used for testing, where we need all support images, query image, \n",
        "# and labels for all sample, so we can calculate per sample metrics, etc.\n",
        "class RetrivalDataset(Dataset):\n",
        "  def __init__(self, data, targets):\n",
        "    # To make the images 28x28x1 instead of 28x28\n",
        "    data = np.expand_dims(data, 2)\n",
        "\n",
        "    self.X = torch.FloatTensor(data)\n",
        "    self.y = torch.LongTensor(targets)\n",
        "\n",
        "        \n",
        "  def __getitem__(self, index):\n",
        "    x = self.X[index]\n",
        "    y = self.y[index]\n",
        "    return x, y\n",
        "  \n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "\n",
        "# This dataset is used for training, \n",
        "# it consists of triplets in order to use the triple loss easily\n",
        "class TripetDataset(Dataset):\n",
        "\n",
        "  # Generate all triplets for all samples\n",
        "  # We hold these triplets in a regular list as some samples can have\n",
        "  # 4 triplets and some can have 6 and we cant have an uneven array/tensor\n",
        "  def __init__(self, data, targets):\n",
        "    all_triplets = []\n",
        "    for i in range(len(data)):\n",
        "      # the x and y\n",
        "      x = data[i]\n",
        "      y = targets[i]\n",
        "\n",
        "      # get the anchor, support, and pos, neg samples\n",
        "      a = x[-1]\n",
        "      support = x[:-1]\n",
        "      pos_samples = support[y == 1]\n",
        "      neg_samples = support[y == 0]\n",
        "\n",
        "      # generate all pairs of positive and negative samples\n",
        "      pairs = itertools.product(pos_samples, neg_samples)\n",
        "      pairs = list(pairs)\n",
        "      pairs = np.array(pairs)\n",
        "\n",
        "      # add the anchor to all pairs to create triplets\n",
        "      sample_triplets = np.insert(pairs, 1, a, axis=1)\n",
        "\n",
        "      # expands the dims so the iamge shape is 1x28x28 not 28x28\n",
        "      sample_triplets = np.expand_dims(sample_triplets, 2)\n",
        "\n",
        "      # add the triplets of this sample to all triplets\n",
        "      all_triplets.append(sample_triplets)\n",
        "\n",
        "    all_triplets = np.array(all_triplets, dtype=object,)\n",
        "    self.triplets = all_triplets\n",
        "\n",
        "  # We return one random triplet from all possible triplets for the sample at index\n",
        "  def __getitem__(self, index):\n",
        "    # get the triplets of this sample\n",
        "    sample_triplets = self.triplets[index]\n",
        "\n",
        "    # select a random index of a triplet\n",
        "    rand_index = np.random.randint(0, len(sample_triplets))\n",
        "\n",
        "    # select a ranom triplet using the index\n",
        "    triplet = sample_triplets[rand_index]\n",
        "    return triplet\n",
        "  \n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.triplets)"
      ],
      "id": "fcf31f45"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qjK9LZXQqVsS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "# Datasets\n",
        "train_dataset = TripetDataset(train_data, train_label)\n",
        "test_dataset = RetrivalDataset(test_data, test_label)\n",
        "\n",
        "# Split the training dataset into training and validation using 0.8 for training\n",
        "valid_split_ratio = 0.1\n",
        "train_size = int(len(train_dataset) * (1 - valid_split_ratio))\n",
        "validation_size = len(train_dataset) - train_size\n",
        "train_dataset, validation_dataset = random_split(train_dataset, [train_size,validation_size])\n",
        "\n",
        "# Data Loaders\n",
        "batch_size=32\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "id": "qjK9LZXQqVsS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LRMP-EwX3AS"
      },
      "source": [
        "## LOSS DEFINITION"
      ],
      "id": "1LRMP-EwX3AS"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "93e6f3fb"
      },
      "outputs": [],
      "source": [
        "class TripletLoss(nn.Module):\n",
        "  def __init__(self, margin):\n",
        "    super(TripletLoss, self).__init__()\n",
        "    self.margin = margin\n",
        "    self.relu = torch.nn.ReLU()\n",
        "\n",
        "  def euc_dist(self, x1, x2):\n",
        "    return (x1 - x2).pow(2).sum(1).pow(1/2)\n",
        "\n",
        "  def forward(self, anchor, pos, neg):\n",
        "    pos_dist = self.euc_dist(anchor, pos)\n",
        "    neg_dist = self.euc_dist(anchor, neg)\n",
        "\n",
        "    losses = pos_dist - neg_dist + self.margin\n",
        "    losses = self.relu(losses)\n",
        "    loss = losses.mean()\n",
        "\n",
        "    return loss"
      ],
      "id": "93e6f3fb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWJve10GYWPI"
      },
      "source": [
        "## MODEL DEFINITION"
      ],
      "id": "EWJve10GYWPI"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b6fdfee",
        "outputId": "fefd6f82-9558-4d15-c50b-5689972b1335"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BestNet(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Dropout(p=0.3, inplace=False)\n",
              "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (11): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (dense_layers): Sequential(\n",
              "    (0): Linear(in_features=1152, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (3): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "## Model Definition ##\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BestNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BestNet, self).__init__()\n",
        "\n",
        "    self.conv_layers = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding='same'),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(2, 2),\n",
        "      nn.Dropout(0.3),\n",
        "\n",
        "      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(2, 2),\n",
        "      nn.Dropout(0.3),\n",
        "\n",
        "      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same'),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(2, 2),\n",
        "      nn.Dropout(0.3),\n",
        "    )\n",
        "\n",
        "    self.dense_layers = nn.Sequential(\n",
        "      nn.Linear(1152, 512),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Linear(512, 128),\n",
        "      nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_layers(x)\n",
        "    x = x.view(x.size()[0], -1)\n",
        "    x = self.dense_layers(x)\n",
        "    return x\n",
        "  \n",
        "\n",
        "model = BestNet()\n",
        "model"
      ],
      "id": "0b6fdfee"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zse7rb4nYHsP"
      },
      "source": [
        "## Trainer & Definitions"
      ],
      "id": "zse7rb4nYHsP"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d2c8f9a6"
      },
      "outputs": [],
      "source": [
        "## Training ##\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "# from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "class Trainer():\n",
        "  def __init__(self,\n",
        "               model: torch.nn.Module,\n",
        "               device: torch.device,\n",
        "               criterion: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               training_DataLoader: torch.utils.data.Dataset,\n",
        "               validation_DataLoader: torch.utils.data.Dataset,\n",
        "               test_DataLoader: torch.utils.data.Dataset,\n",
        "               epochs: int,\n",
        "               patience: int, \n",
        "              ):\n",
        "      \n",
        "    self.model = model\n",
        "    self.criterion = criterion\n",
        "    self.optimizer = optimizer\n",
        "    self.training_DataLoader = training_DataLoader\n",
        "    self.validation_DataLoader = validation_DataLoader\n",
        "    self.test_DataLoader = test_DataLoader\n",
        "    self.device = device\n",
        "    self.epochs = epochs\n",
        "    self.patience = patience\n",
        "\n",
        "  def __str__(self):\n",
        "    info = [\n",
        "      f'device: {self.device}',\n",
        "      f'epochs: {self.epochs}',\n",
        "      f'criterion: {self.criterion}',\n",
        "      f'patience: {self.patience}',\n",
        "      f'optimizer: {self.optimizer}',\n",
        "    ]\n",
        "\n",
        "    trainer_str = \"\\n\".join(info)\n",
        "    return trainer_str\n",
        "\n",
        "\n",
        "  def run_train_step(self, epoch, pbar):\n",
        "    train_losses=[]\n",
        "    self.model.train()\n",
        "    for batch in self.training_DataLoader:\n",
        "      # zerograd the parameters\n",
        "      self.optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "      # Get the data and move it to device\n",
        "      batch = batch.to(self.device)\n",
        "\n",
        "      # flatten the batch so we can pass it through the model\n",
        "      batch = batch.flatten(0,1)\n",
        "\n",
        "      # forward pass\n",
        "      e_batch = self.model(batch)\n",
        "\n",
        "      # unflatten the result so we can use it in the loss\n",
        "      e_batch = e_batch.unflatten(0, (-1, 3))\n",
        "      e_a, e_p, e_n = e_batch[:,0], e_batch[:,1], e_batch[:,2]\n",
        "      \n",
        "      # calculate loss\n",
        "      loss = self.criterion(e_a, e_p, e_n)  # calculate loss\n",
        "      loss_value = loss.item()\n",
        "      train_losses.append(loss_value)\n",
        "\n",
        "      # backprop  \n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "      \n",
        "      # Update the loss on the progress bar\n",
        "      pbar.set_postfix({f\"Loss\": f\"{np.mean(train_losses):.4f}\"})\n",
        "      pbar.update()\n",
        "\n",
        "    return train_losses\n",
        "\n",
        "\n",
        "  def run_eval_step(self):\n",
        "    valid_losses = []\n",
        "    self.model.eval()\n",
        "    for batch in self.validation_DataLoader:\n",
        "      # Get the data and move it to device\n",
        "      batch = batch.to(self.device)\n",
        "\n",
        "      # flatten the batch so we can pass it through the model\n",
        "      batch = batch.flatten(0,1)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        # forward pass\n",
        "        e_batch = self.model(batch)\n",
        "\n",
        "        # unflatten the result so we can use it in the loss\n",
        "        e_batch = e_batch.unflatten(0, (-1, 3))\n",
        "        e_a, e_p, e_n = e_batch[:,0], e_batch[:,1], e_batch[:,2]\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = self.criterion(e_a, e_p, e_n)  # calculate loss\n",
        "        loss_value = loss.item()\n",
        "        valid_losses.append(loss_value)\n",
        "\n",
        "    return valid_losses\n",
        "\n",
        "\n",
        "  def run_trainer(self):\n",
        "    stop = False\n",
        "    best_val_loss = np.inf\n",
        "    remaining_patience = self.patience\n",
        "    # For number of epochs\n",
        "    for epoch in range(self.epochs):\n",
        "      # progress bar\n",
        "      with tqdm(self.training_DataLoader, position=0) as pbar:\n",
        "        # the label of the progress bar\n",
        "        pbar.set_description_str(f'Epoch {epoch + 1}/{self.epochs}')\n",
        "\n",
        "        # train phase\n",
        "        train_losses = self.run_train_step(epoch, pbar)\n",
        "        \n",
        "        # validation phase\n",
        "        val_losses = self.run_eval_step()\n",
        "\n",
        "        # loss calculations\n",
        "        loss = np.mean(train_losses)\n",
        "        val_loss = np.mean(val_losses)\n",
        "\n",
        "        # Print training and validation loss\n",
        "        pbar.set_postfix({f\"Loss\": f\"{loss:.4f}\", f\"Val-Loss\": f\"{val_loss:.4f}\"})\n",
        "\n",
        "        # early stopping\n",
        "        if val_loss > best_val_loss:\n",
        "          remaining_patience -= 1\n",
        "          if remaining_patience <= 0:\n",
        "            break\n",
        "        else:\n",
        "          remaining_patience = self.patience\n",
        "          best_val_loss = val_loss\n",
        "          torch.save(self.model.state_dict(), model_path)"
      ],
      "id": "d2c8f9a6"
    },
    {
      "cell_type": "code",
      "source": [
        "def run_test(model, data_loader, device, threshold):\n",
        "  dataLoader = data_loader\n",
        "  predictions = []\n",
        "  labels = []\n",
        "  model.eval()\n",
        "\n",
        "  # define pairwiseDistance function\n",
        "  pdist = torch.nn.PairwiseDistance(p=2.0, eps=1e-06, keepdim=False)\n",
        "\n",
        "  # don't update the gradients\n",
        "  with torch.no_grad():\n",
        "    # for every batch\n",
        "    for batch in dataLoader:\n",
        "      x, y = batch\n",
        "      x.to(device)\n",
        "\n",
        "      # flatten x in order to pass it through the model\n",
        "      x = x.flatten(0,1)\n",
        "\n",
        "      # pass it through the model to get the embeddings\n",
        "      e_x = model(x)\n",
        "\n",
        "      # unflatten the 0th dimension so we get batches images dimensions back\n",
        "      e_x = e_x.unflatten(0, (-1, 6))\n",
        "\n",
        "      # get the support and the query images\n",
        "      supports = e_x[:,-1].unsqueeze(1)\n",
        "      queries = e_x[:,:-1]\n",
        "\n",
        "      # find the distances\n",
        "      dist = pdist(supports, queries)\n",
        "\n",
        "      # using the threshold determine the predictions\n",
        "      pred = dist[:] < threshold\n",
        "\n",
        "      # append the prections and the labels\n",
        "      predictions.append(pred)\n",
        "      labels.append(y)\n",
        "\n",
        "  predictions = np.concatenate(predictions).reshape((-1))\n",
        "  labels = np.concatenate(labels).reshape((-1))\n",
        "\n",
        "  cr = classification_report(labels, predictions)\n",
        "  print(cr) "
      ],
      "metadata": {
        "id": "E6_CFB4r03Vi"
      },
      "id": "E6_CFB4r03Vi",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_threshold(model, data_loader, device):\n",
        "  dataLoader = data_loader\n",
        "  predictions = []\n",
        "  labels = []\n",
        "  model.eval()\n",
        "\n",
        "  # define pairwiseDistance function\n",
        "  pdist = torch.nn.PairwiseDistance(p=2.0, eps=1e-06, keepdim=False)\n",
        "\n",
        "  # define float zero\n",
        "  zero = torch.torch.tensor(0, dtype=torch.float32)\n",
        "\n",
        "  # accumulate thresholds\n",
        "  thresholds = []\n",
        "\n",
        "  # don't update the gradients\n",
        "  with torch.no_grad():\n",
        "    # for every batch\n",
        "    for batch in dataLoader:\n",
        "      x, y = batch\n",
        "      x.to(device)\n",
        "\n",
        "      # flatten x in order to pass it through the model\n",
        "      x = x.flatten(0,1)\n",
        "\n",
        "      # pass it through the model to get the embeddings\n",
        "      e_x = model(x)\n",
        "\n",
        "      # unflatten the 0th dimension so we get batches images dimensions back\n",
        "      e_x = e_x.unflatten(0, (-1, 6))\n",
        "\n",
        "      # get the support and the query images\n",
        "      supports = e_x[:,-1].unsqueeze(1)\n",
        "      queries = e_x[:,:-1]\n",
        "\n",
        "      # find the distances\n",
        "      dist = pdist(supports, queries)\n",
        "\n",
        "      # find the mean similarity of pos examples\n",
        "      pos_examples = torch.where(y == 1, dist, zero)\n",
        "      pos_mean = torch.sum(pos_examples) / torch.count_nonzero(pos_examples)\n",
        "\n",
        "      # find the mean similarity of neg examples\n",
        "      neg_examples = torch.where(y == 0, dist, zero)\n",
        "      neg_mean = torch.sum(neg_examples) / torch.count_nonzero(neg_examples)\n",
        "\n",
        "      # calculate the threshold\n",
        "      threshold = (pos_mean + neg_mean) / 2\n",
        "\n",
        "      # store the threshold for the batch\n",
        "      thresholds.append(threshold)\n",
        "\n",
        "    final_threshold = np.mean(thresholds)\n",
        "\n",
        "  return final_threshold"
      ],
      "metadata": {
        "id": "e7mYxMp6o7dX"
      },
      "id": "e7mYxMp6o7dX",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "I_E_cZCJIaz3"
      },
      "id": "I_E_cZCJIaz3"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mlRRzxpJ7hVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed6f0a0-7286-4de1-9f9c-1c84ed447d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "epochs: 60\n",
            "criterion: TripletLoss(\n",
            "  (relu): ReLU()\n",
            ")\n",
            "patience: 10\n",
            "optimizer: AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0.01\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# TRAINER DEFINITION\n",
        "\n",
        "# device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(device)\n",
        "    \n",
        "# model save file\n",
        "model_path = 'saved_model'\n",
        "\n",
        "# model\n",
        "model = BestNet().double().to(device)\n",
        "\n",
        "# epochs\n",
        "epochs = 60\n",
        "\n",
        "# margin value\n",
        "margin=1\n",
        "\n",
        "# loss\n",
        "criterion = TripletLoss(margin)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters())\n",
        "\n",
        "# trainer\n",
        "trainer = Trainer(model=model,\n",
        "                  device=device,\n",
        "                  criterion=criterion,\n",
        "                  optimizer=optimizer,\n",
        "                  training_DataLoader=train_loader,\n",
        "                  validation_DataLoader=validation_loader,\n",
        "                  test_DataLoader=test_loader,\n",
        "                  epochs=epochs,\n",
        "                  patience=10,\n",
        "                  )\n",
        "\n",
        "print(trainer)"
      ],
      "id": "mlRRzxpJ7hVq"
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "\n",
        "trainer.run_trainer()"
      ],
      "metadata": {
        "id": "I5mJTkofA-9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62cb98b8-ef3d-432c-8d04-01c0b53b75ed"
      },
      "id": "I5mJTkofA-9W",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/60: 100%|██████████| 282/282 [00:11<00:00, 24.83it/s, Loss=0.5524, Val-Loss=0.3260]\n",
            "Epoch 2/60: 100%|██████████| 282/282 [00:11<00:00, 25.57it/s, Loss=0.3176, Val-Loss=0.2209]\n",
            "Epoch 3/60: 100%|██████████| 282/282 [00:11<00:00, 25.58it/s, Loss=0.2644, Val-Loss=0.1825]\n",
            "Epoch 4/60: 100%|██████████| 282/282 [00:10<00:00, 25.67it/s, Loss=0.2231, Val-Loss=0.1776]\n",
            "Epoch 5/60: 100%|██████████| 282/282 [00:10<00:00, 25.68it/s, Loss=0.1951, Val-Loss=0.1460]\n",
            "Epoch 6/60: 100%|██████████| 282/282 [00:10<00:00, 25.67it/s, Loss=0.1694, Val-Loss=0.1182]\n",
            "Epoch 7/60: 100%|██████████| 282/282 [00:11<00:00, 25.56it/s, Loss=0.1490, Val-Loss=0.1160]\n",
            "Epoch 8/60: 100%|██████████| 282/282 [00:10<00:00, 25.65it/s, Loss=0.1374, Val-Loss=0.0998]\n",
            "Epoch 9/60: 100%|██████████| 282/282 [00:10<00:00, 25.67it/s, Loss=0.1292, Val-Loss=0.0959]\n",
            "Epoch 10/60: 100%|██████████| 282/282 [00:10<00:00, 25.68it/s, Loss=0.1180, Val-Loss=0.0788]\n",
            "Epoch 11/60: 100%|██████████| 282/282 [00:10<00:00, 25.71it/s, Loss=0.1092, Val-Loss=0.0759]\n",
            "Epoch 12/60: 100%|██████████| 282/282 [00:10<00:00, 25.68it/s, Loss=0.1054, Val-Loss=0.0778]\n",
            "Epoch 13/60: 100%|██████████| 282/282 [00:11<00:00, 25.59it/s, Loss=0.0972, Val-Loss=0.0707]\n",
            "Epoch 14/60: 100%|██████████| 282/282 [00:11<00:00, 25.61it/s, Loss=0.0886, Val-Loss=0.0642]\n",
            "Epoch 15/60: 100%|██████████| 282/282 [00:11<00:00, 25.60it/s, Loss=0.0868, Val-Loss=0.0555]\n",
            "Epoch 16/60: 100%|██████████| 282/282 [00:11<00:00, 25.64it/s, Loss=0.0815, Val-Loss=0.0704]\n",
            "Epoch 17/60: 100%|██████████| 282/282 [00:11<00:00, 25.38it/s, Loss=0.0778, Val-Loss=0.0525]\n",
            "Epoch 18/60: 100%|██████████| 282/282 [00:11<00:00, 25.60it/s, Loss=0.0717, Val-Loss=0.0467]\n",
            "Epoch 19/60: 100%|██████████| 282/282 [00:11<00:00, 25.63it/s, Loss=0.0730, Val-Loss=0.0515]\n",
            "Epoch 20/60: 100%|██████████| 282/282 [00:11<00:00, 25.63it/s, Loss=0.0723, Val-Loss=0.0495]\n",
            "Epoch 21/60: 100%|██████████| 282/282 [00:11<00:00, 25.64it/s, Loss=0.0655, Val-Loss=0.0599]\n",
            "Epoch 22/60: 100%|██████████| 282/282 [00:11<00:00, 25.63it/s, Loss=0.0649, Val-Loss=0.0530]\n",
            "Epoch 23/60: 100%|██████████| 282/282 [00:11<00:00, 25.61it/s, Loss=0.0578, Val-Loss=0.0638]\n",
            "Epoch 24/60: 100%|██████████| 282/282 [00:11<00:00, 25.60it/s, Loss=0.0555, Val-Loss=0.0549]\n",
            "Epoch 25/60: 100%|██████████| 282/282 [00:11<00:00, 25.55it/s, Loss=0.0568, Val-Loss=0.0486]\n",
            "Epoch 26/60: 100%|██████████| 282/282 [00:11<00:00, 25.51it/s, Loss=0.0547, Val-Loss=0.0430]\n",
            "Epoch 27/60: 100%|██████████| 282/282 [00:11<00:00, 25.56it/s, Loss=0.0554, Val-Loss=0.0481]\n",
            "Epoch 28/60: 100%|██████████| 282/282 [00:11<00:00, 25.51it/s, Loss=0.0499, Val-Loss=0.0332]\n",
            "Epoch 29/60: 100%|██████████| 282/282 [00:11<00:00, 25.58it/s, Loss=0.0518, Val-Loss=0.0576]\n",
            "Epoch 30/60: 100%|██████████| 282/282 [00:11<00:00, 25.57it/s, Loss=0.0450, Val-Loss=0.0377]\n",
            "Epoch 31/60: 100%|██████████| 282/282 [00:11<00:00, 25.57it/s, Loss=0.0480, Val-Loss=0.0342]\n",
            "Epoch 32/60: 100%|██████████| 282/282 [00:11<00:00, 25.58it/s, Loss=0.0469, Val-Loss=0.0526]\n",
            "Epoch 33/60: 100%|██████████| 282/282 [00:11<00:00, 25.58it/s, Loss=0.0467, Val-Loss=0.0435]\n",
            "Epoch 34/60: 100%|██████████| 282/282 [00:11<00:00, 25.59it/s, Loss=0.0443, Val-Loss=0.0461]\n",
            "Epoch 35/60: 100%|██████████| 282/282 [00:11<00:00, 25.50it/s, Loss=0.0410, Val-Loss=0.0325]\n",
            "Epoch 36/60: 100%|██████████| 282/282 [00:11<00:00, 25.54it/s, Loss=0.0371, Val-Loss=0.0564]\n",
            "Epoch 37/60: 100%|██████████| 282/282 [00:11<00:00, 25.57it/s, Loss=0.0381, Val-Loss=0.0529]\n",
            "Epoch 38/60: 100%|██████████| 282/282 [00:11<00:00, 25.57it/s, Loss=0.0360, Val-Loss=0.0429]\n",
            "Epoch 39/60: 100%|██████████| 282/282 [00:11<00:00, 25.56it/s, Loss=0.0357, Val-Loss=0.0459]\n",
            "Epoch 40/60: 100%|██████████| 282/282 [00:11<00:00, 25.58it/s, Loss=0.0330, Val-Loss=0.0484]\n",
            "Epoch 41/60: 100%|██████████| 282/282 [00:11<00:00, 25.57it/s, Loss=0.0357, Val-Loss=0.0501]\n",
            "Epoch 42/60: 100%|██████████| 282/282 [00:11<00:00, 25.56it/s, Loss=0.0338, Val-Loss=0.0363]\n",
            "Epoch 43/60: 100%|██████████| 282/282 [00:11<00:00, 25.57it/s, Loss=0.0330, Val-Loss=0.0473]\n",
            "Epoch 44/60: 100%|██████████| 282/282 [00:11<00:00, 25.57it/s, Loss=0.0335, Val-Loss=0.0495]\n",
            "Epoch 45/60: 100%|██████████| 282/282 [00:11<00:00, 25.57it/s, Loss=0.0363, Val-Loss=0.0419]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "cwyIYliyIdBf"
      },
      "id": "cwyIYliyIdBf"
    },
    {
      "cell_type": "code",
      "source": [
        "model = BestNet()\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYauY1nS7vd7",
        "outputId": "80709a70-f41a-4853-9649-8ebbf6b1cb86"
      },
      "id": "zYauY1nS7vd7",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_dataset = RetrivalDataset(train_data, train_label)\n",
        "threshold_loader = torch.utils.data.DataLoader(threshold_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "threshold = determine_threshold(model, threshold_loader, device)\n",
        "print(threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSxhaX6C7tIb",
        "outputId": "573b82d5-4711-4e9d-8e7a-410ed1989615"
      },
      "id": "qSxhaX6C7tIb",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.559809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBp-7MBe10UM",
        "outputId": "c4a0fb8a-b2b3-4e98-e6ca-a1f2ef69a674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95      3057\n",
            "           1       0.90      0.94      0.92      1943\n",
            "\n",
            "    accuracy                           0.94      5000\n",
            "   macro avg       0.93      0.94      0.94      5000\n",
            "weighted avg       0.94      0.94      0.94      5000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "run_test(model, test_loader, device, threshold)"
      ],
      "id": "IBp-7MBe10UM"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7c03FZYN_lAz",
        "EWJve10GYWPI"
      ],
      "name": "2AMM10 Deep Learning - Assignment 01",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}